## **Семинар №2. Собираем быстрый пайплайн данных**

**Цель семинара:**
Освоить практические методы построения эффективного видеопайплайна — от параллельного чтения и сэмплинга кадров до профилирования latency и оптимизации throughput. Все задания выполняются в Python с использованием PyTorch, PyAV и инструментов профилирования.

---

### **Задача 1. Базовый декодер видеокадров**

Реализуйте функцию чтения кадров из видео с помощью PyAV:

```python
def read_clip(filename, start=0, num_frames=16, stride=2):
    ...
```

Функция должна возвращать `numpy.ndarray` формы `(T, H, W, 3)`.
Проверьте корректность длины клипа при разных stride и выведите фактическую частоту кадров.

**Проверка:** выведите индексы кадров, попавших в выборку, и визуализируйте первый и последний кадры клипа.

---

### **Задача 2. Реализация Dataset для видеоклипов**

Создайте класс `VideoDataset`, который принимает список видеофайлов и реализует метод `__getitem__`, возвращающий один клип фиксированной длины.
Добавьте аргументы:

* `clip_len` — число кадров,
* `stride` — шаг между кадрами,
* `transform` — пайплайн препроцессинга.

Проверьте работу с `torch.utils.data.DataLoader`, задав `batch_size=4`.

---

### **Задача 3. Параллельная загрузка данных**

Добавьте параметр `num_workers` в `DataLoader` и измерьте время одной эпохи при значениях `1, 2, 4, 8`.
Постройте график зависимости throughput (кадров/с) от числа потоков.
Определите, при каком `num_workers` достигается насыщение производительности.

---

### **Задача 4. Профилирование этапов пайплайна**

С помощью `torch.profiler` измерьте время выполнения стадий:

1. декодирования (`read_clip`);
2. препроцессинга (resize, normalize);
3. инференса (заглушка `model = lambda x: x.mean()`).

Отобразите timeline-график в TensorBoard и найдите соотношение $L_{dec}:L_{prep}:L_{inf}$.

---

### **Задача 5. Prefetch и pinned memory**

Добавьте к `DataLoader` параметры `prefetch_factor=2` и `pin_memory=True`.
Сравните средний FPS и jitter до и после включения этих опций.
Поясните, как pinned memory влияет на передачу данных между CPU и GPU.

---

### **Задача 6. Pipeline overlap**

Модифицируйте код так, чтобы декодирование и инференс выполнялись в разных потоках.
Используйте `torch.cuda.Stream` и `multiprocessing.Queue`.
Измерьте разницу в среднем latency между последовательным и перекрытым исполнением.

---

### **Задача 7. Аппаратное декодирование**

Если доступна GPU с поддержкой NVDEC, используйте `decord.VideoReader` с `ctx=decord.gpu(0)`.
Сравните время декодирования для PyAV (CPU) и decord (GPU).
Выведите таблицу:

| Метод | Среднее время декодирования (мс) | FPS |
| ----- | -------------------------------- | --- |

---

### **Задача 8. Оптимизация препроцессинга**

Реализуйте вариант препроцессинга на GPU через `torchvision.transforms.v2`.
Сравните общую латентность с вариантом на CPU.
Постройте столбчатую диаграмму времени на этапах decode / transform / infer.

---

### **Задача 9. Измерение стабильности FPS**

Добавьте измерение мгновенного FPS и коэффициента вариации:
$$
CV = \frac{\sigma_{FPS}}{\mu_{FPS}}.
$$

Запишите значения FPS за 100 итераций и постройте график.
Определите, при каком размере батча и глубине очереди FPS становится стабильным ($CV < 0.05$).

---

### **Задача 10. Финальное задание: мини-RT пайплайн**

Соберите полный поток `decode → preprocess → infer → visualize`, работающий в near-real-time на одном видеофайле или RTSP-потоке.
Реализуйте двухуровневую очередь (frames и clips), используйте pinned memory и CUDA Streams.
Измерьте итоговые метрики:
`
* средний FPS,
* $L_{p95}$,
* jitter.

Оформите результаты в виде отчёта с графиками и пояснениями к оптимизациям.`

---

### **Мини-ДЗ (по Plan.md):**

Рефакторинг пайплайна под два режима:

1. **offline** (файловый ввод),
2. **near-real-time** (потоковый ввод).
   Сравните latency и стабильность FPS, представьте выводы в таблице и кратких комментариях.

---